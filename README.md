the code main.py is a sample implementation to create multi-modal model for differential diagnosis prediction.     with various other techniques the code can reach much higher accuracy.   This form of model is necessity in creating accurate and high f1scores

context:
The code is simplified pytorch implementation of our split learning project

Electronic health data is decentralized, spread across many institutions, and often incomplete or missing timely demographic info. This limits vital research, especially for emerging diseases like COVID-19. Health Information Exchanges (HIEs) collecting patient-level data from over 60% of US hospitals offer a powerful resource, but strict privacy and technical barriers hamper data sharing. Enter split learning: a cutting-edge technique that keeps sensitive information secure while enabling collaborative model training across organizations. By letting HIEs pool insights without revealing raw data, split learning promises a more efficient, fast, privacy-preserving approach to modern healthcare research.  It is the fastest among privacy preserving deep learning techniques.

Under the 21st Century Cures Act, USCDI defines core data elements and clinical notes to ensure consistent sharing of health information. FHIR, developed by HL7, enhances interoperability by providing standardized APIs for data exchange and supporting large-scale data exports. Our project leverages these standards to access patient data from three HIEs, ensuring secure, efficient data integration. To investigate adverse health outcomes after COVID-19 diagnoses, we identified essential data elements including demographics, vital signs, conditions, lab observations, and procedures using recognized terminologies like SNOMED CT, ICD-10-CM, and LOINC. We combined existing VSAC value sets with custom-built ones to cover gaps in standard definitions, then converted them into FHIR ValueSet resources.

Our split learning setup uses WebSockets (over TLS 1.3+) to securely connect HIEs with a central server, orchestrated via FastAPI. Each HIE and central server runs stunnel forward and reverse proxy for encrypted connections ensuring mutual TLS authentication. Redis stores registration via OTP and validation details, controlling node participation and processing order. During training, HIEs perform local forward passes and send serialized tensors to the central server (after distance decorrelation using a distance loss function) which aggregates gradients, updates model parameters, and returns them without exposing raw patient data between HIEs. This multi-layered security ensures strict node registration and secure communication while facilitating collaborative AI.

Challenges included securing participation from three HIEs involved extensive negotiations, as we moved this theoretical technology into production. Contractual obligations strictly forbade raw data movement between HIEs or using a shared secure network, prompting a shift from PyTorch's RPC to a WebSocket-based client-server model. Another challenge: FHIR resource mapping had to be performed without direct data access, necessitating collaboration with each HIE's data experts. The design team's familiarity with health data standards was crucial, and aggregate level QA checks included comparing disease counts against CDC reports. In preliminary tests using a multilabel classification approach on 50,000 patients, the model achieved an f1score of .7742 after approximately 500 epochs, indicating promising potential for scalable, privacy-preserving deep learning.

Moving forward, we aim to strengthen privacy and efficiency across split learning deployments by integrating a differential privacy inspired activation function with real-time privacy scoring and an attack vector testing framework. We invite the healthcare research community to build upon these enhancements, refining secure, high-performance split learning approaches for broader impact and collaboration.

Code: https://github.com/onc-healthit/ml-covid-hie-pcor
